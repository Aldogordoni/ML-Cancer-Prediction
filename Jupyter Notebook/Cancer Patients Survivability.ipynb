{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6631ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0       1       2       3       4       5       6   \\\n",
      "initial_weight        60      70     210     540     900     660     390   \n",
      "age_at_diagnosis   25041   21901   30643   22575   32415   26971   20318   \n",
      "vital_status       Alive   Alive    Dead   Alive    Dead   Alive   Alive   \n",
      "age_at_index          68      59      83      61      88      73      55   \n",
      "days_to_birth     -25041  -21901  -30643  -22575  -32415  -26971  -20318   \n",
      "\n",
      "                      7       8       9   ...      47      48      49      50  \\\n",
      "initial_weight       350    1010     290  ...     400     170     300     340   \n",
      "age_at_diagnosis   22650   27688   25791  ...   29658   23826   25386   26054   \n",
      "vital_status        Dead    Dead    Dead  ...    Dead    Dead   Alive   Alive   \n",
      "age_at_index          62      75      70  ...      81      65      69      71   \n",
      "days_to_birth     -22650  -27688  -25791  ...  -29658  -23826  -25386  -26054   \n",
      "\n",
      "                      51      52      53      54      55      56  \n",
      "initial_weight       160     120     250     890     180     420  \n",
      "age_at_diagnosis   25360   32058   22886   24124   22978   25419  \n",
      "vital_status       Alive    Dead    Dead   Alive   Alive   Alive  \n",
      "age_at_index          69      87      62      66      62      69  \n",
      "days_to_birth     -25360  -32058  -22886  -24124  -22978  -25419  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "#importing the dataset\n",
    "import pandas as pd\n",
    "\n",
    "hdr = list(range(0, 57))\n",
    "temp_df = pd.read_table('ML Engineer Candidate Prompt Dataset.txt', delimiter='\\t',names = hdr,  low_memory = False)\n",
    "print(temp_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dcab8330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_weight       object\n",
      "age_at_diagnosis     object\n",
      "vital_status         object\n",
      "age_at_index         object\n",
      "days_to_birth        object\n",
      "                      ...  \n",
      "ENSG00000288669.1    object\n",
      "ENSG00000288670.1    object\n",
      "ENSG00000288671.1    object\n",
      "ENSG00000288674.1    object\n",
      "ENSG00000288675.1    object\n",
      "Length: 60670, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#transpose table\n",
    "temp_df = temp_df.transpose()\n",
    "print(temp_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0780dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully saved\n"
     ]
    }
   ],
   "source": [
    "#saving fixed table\n",
    "temp_df.to_csv('fixed_table')\n",
    "print(\"File successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fe126837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_weight        int64\n",
      "age_at_diagnosis      int64\n",
      "vital_status         object\n",
      "age_at_index          int64\n",
      "days_to_birth         int64\n",
      "                      ...  \n",
      "ENSG00000288669.1     int64\n",
      "ENSG00000288670.1     int64\n",
      "ENSG00000288671.1     int64\n",
      "ENSG00000288674.1     int64\n",
      "ENSG00000288675.1     int64\n",
      "Length: 60670, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#opening the fixed table\n",
    "df = pd.read_csv('fixed_table', low_memory=False)\n",
    "df.drop(columns=df.columns[0], axis=1,inplace=True)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3b5f902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df['demographic_id'] = le.fit_transform(df['demographic_id'])\n",
    "df['vital_status'] = le.fit_transform(df['vital_status'])\n",
    "df['paper_clinical_stage'] = le.fit_transform(df['paper_clinical_stage'])\n",
    "df['year_of_death'] = le.fit_transform(df['year_of_death'])\n",
    "df['days_to_death'] = le.fit_transform(df['days_to_death'])\n",
    "#E.g. vital_status has been encoded to be 0 for alive and 1 for dead\n",
    "print(df['vital_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "271eb3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age_at_diagnosis  age_at_index  days_to_birth  year_of_birth  \\\n",
      "0             25041            68         -25041           1940   \n",
      "1             21901            59         -21901           1952   \n",
      "2             30643            83         -30643           1926   \n",
      "\n",
      "   demographic_id  paper_clinical_stage  ENSG00000000003.15  \\\n",
      "0              45                     0                4511   \n",
      "1              16                     0                6035   \n",
      "2              11                     2                5583   \n",
      "\n",
      "   ENSG00000000005.6  ENSG00000000419.13  ENSG00000000457.14  ...  \\\n",
      "0                402                1433                 201  ...   \n",
      "1                 23                1886                 775  ...   \n",
      "2                  8                2542                 946  ...   \n",
      "\n",
      "   ENSG00000288661.1  ENSG00000288662.1  ENSG00000288663.1  ENSG00000288665.1  \\\n",
      "0                  0                  0                  4                  0   \n",
      "1                  0                  0                 70                  0   \n",
      "2                  0                  0                 38                  0   \n",
      "\n",
      "   ENSG00000288667.1  ENSG00000288669.1  ENSG00000288670.1  ENSG00000288671.1  \\\n",
      "0                  0                  8                 77                  0   \n",
      "1                  2                  0                110                  0   \n",
      "2                  0                  0                342                  0   \n",
      "\n",
      "   ENSG00000288674.1  ENSG00000288675.1  \n",
      "0                  4                 60  \n",
      "1                  9                 59  \n",
      "2                  3                 23  \n",
      "\n",
      "[3 rows x 60666 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "Name: vital_status, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#preparing the data in X and y sets\n",
    "X = df.drop(columns = ['initial_weight','vital_status', 'year_of_death','days_to_death'])\n",
    "y = df['vital_status']\n",
    "print(X.head(3))\n",
    "print(y.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6bdee86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing data into sets to be trained and tested at a 20% test size\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "87c032d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.04942169  1.08117346 -1.04942169 ...  0.          1.21857244\n",
      "   0.21663464]\n",
      " [-0.97772819 -0.9251278   0.97772819 ...  0.         -1.52321555\n",
      "   0.73152331]\n",
      " [-0.12664107 -0.1226073   0.12664107 ...  0.          1.44705477\n",
      "   0.01067917]\n",
      " ...\n",
      " [-0.54775188 -0.52386755  0.54775188 ...  0.         -0.15232156\n",
      "   1.79562657]\n",
      " [ 1.81323912  1.7833789  -1.81323912 ...  0.         -0.60928622\n",
      "  -0.53853541]\n",
      " [ 1.32231257  1.28180358 -1.32231257 ...  0.         -0.83776855\n",
      "  -0.91612044]]\n"
     ]
    }
   ],
   "source": [
    "#Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ca558675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Decision Tree Classifier 1.0\n",
      "1 - Random Forest Classifier 1.0\n",
      "2 - SVC (linear k) 1.0\n",
      "3 - SVC (RBF) 0.9555555555555556\n",
      "4 - Logistic Regression 1.0\n",
      "5 - Gaussian NB 1.0\n",
      "6 - K-Neighbours 0.8\n"
     ]
    }
   ],
   "source": [
    "#Preparing and training the models\n",
    "#Creating a function to train all models at once\n",
    "\n",
    "def models(X_train, y_train):\n",
    "    #0 = Decision Tree Classifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    dtc.fit(X_train,y_train)\n",
    "    \n",
    "    #1 = Random Forest Classifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rfc = RandomForestClassifier(n_estimators=10, criterion = 'entropy', random_state = 0)\n",
    "    rfc.fit(X_train,y_train)\n",
    "\n",
    "    #2 = SVC (linear k)\n",
    "    from sklearn.svm import SVC\n",
    "    svc_ln = SVC(kernel='linear', random_state = 0)\n",
    "    svc_ln.fit(X_train,y_train)\n",
    "    \n",
    "    #3 = SVC (RBF)\n",
    "    from sklearn.svm import SVC\n",
    "    svc_rbf = SVC(kernel='rbf', random_state = 0)\n",
    "    svc_rbf.fit(X_train,y_train)\n",
    "\n",
    "    #4 = Logistic Regression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lreg = LogisticRegression(random_state = 0)\n",
    "    lreg.fit(X_train,y_train)\n",
    "\n",
    "    #5 = Gaussian NB\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "\n",
    "    #6 = K-Neighbours\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knc = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "    knc.fit(X_train,y_train)\n",
    "    \n",
    "    #print the accuracy of each model\n",
    "    print('0 - Decision Tree Classifier', dtc.score(X_train, y_train))\n",
    "    print('1 - Random Forest Classifier', rfc.score(X_train, y_train))\n",
    "    print('2 - SVC (linear k)', svc_ln.score(X_train, y_train))\n",
    "    print('3 - SVC (RBF)', svc_rbf.score(X_train, y_train))\n",
    "    print('4 - Logistic Regression', lreg.score(X_train, y_train))\n",
    "    print('5 - Gaussian NB', gnb.score(X_train, y_train))\n",
    "    print('6 - K-Neighbours', knc.score(X_train, y_train))\n",
    "    \n",
    "    return dtc, rfc, svc_ln, svc_rbf, lreg, gnb, knc\n",
    "\n",
    "model = models(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f13db2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully\n"
     ]
    }
   ],
   "source": [
    "#Saving models\n",
    "import joblib\n",
    "joblib.dump(model[0], 'Decision Tree Classifier')\n",
    "joblib.dump(model[1], 'Random Forest Classifier')\n",
    "joblib.dump(model[2], 'SVC (linear k)')\n",
    "joblib.dump(model[3], 'SVC (RBF)')\n",
    "joblib.dump(model[4], 'Logistic Regression')\n",
    "joblib.dump(model[5], 'Gaussian NB')\n",
    "joblib.dump(model[6], 'K-Neighbours')\n",
    "print(\"Models saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "944eed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "#Loading models\n",
    "import joblib\n",
    "import numpy as np\n",
    "models = np.empty(7, dtype=object)\n",
    "models[0] = joblib.load('Decision Tree Classifier')\n",
    "models[1] = joblib.load('Random Forest Classifier')\n",
    "models[2] = joblib.load('SVC (linear k)')\n",
    "models[3] = joblib.load('SVC (RBF)')\n",
    "models[4] = joblib.load('Logistic Regression')\n",
    "models[5] = joblib.load('Gaussian NB')\n",
    "models[6] = joblib.load('K-Neighbours')\n",
    "\n",
    "model = models\n",
    "print(\"Models Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "391b0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [2 3]]\n",
      "Model[0] Testing Accuracy = \"0.5\" \n",
      "\n",
      "[[5 2]\n",
      " [3 2]]\n",
      "Model[1] Testing Accuracy = \"0.5833333333333334\" \n",
      "\n",
      "[[0 7]\n",
      " [1 4]]\n",
      "Model[2] Testing Accuracy = \"0.3333333333333333\" \n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "Model[3] Testing Accuracy = \"0.4166666666666667\" \n",
      "\n",
      "[[0 7]\n",
      " [1 4]]\n",
      "Model[4] Testing Accuracy = \"0.3333333333333333\" \n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "Model[5] Testing Accuracy = \"0.4166666666666667\" \n",
      "\n",
      "[[0 7]\n",
      " [1 4]]\n",
      "Model[6] Testing Accuracy = \"0.3333333333333333\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in range(len(model)):\n",
    "    cm = confusion_matrix(y_test, model[i].predict(X_test))\n",
    "    \n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, model[i].predict(X_test)).ravel()\n",
    "    \n",
    "    score = (TP+TN)/(TP+TN+FN+FP)\n",
    "    print(cm)\n",
    "    print('Model[{}] Testing Accuracy = \"{}\"'.format(i, score),\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c09c3825",
   "metadata": {},
   "source": [
    "#importing the dataset\n",
    "import pandas as pd\n",
    "\n",
    "hdr = list(range(0, 57))\n",
    "temp_df = pd.read_table('ML Engineer Candidate Prompt Dataset.txt', delimiter='\\t',names = hdr,  low_memory = False)\n",
    "print(temp_df.head(5))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a585b30",
   "metadata": {},
   "source": [
    "#transpose table\n",
    "temp_df = temp_df.transpose()\n",
    "print(temp_df.dtypes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe49f212",
   "metadata": {},
   "source": [
    "#saving fixed table\n",
    "temp_df.to_csv('fixed_table')\n",
    "print(\"File successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe126837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_weight        int64\n",
      "age_at_diagnosis      int64\n",
      "vital_status         object\n",
      "age_at_index          int64\n",
      "days_to_birth         int64\n",
      "                      ...  \n",
      "ENSG00000288669.1     int64\n",
      "ENSG00000288670.1     int64\n",
      "ENSG00000288671.1     int64\n",
      "ENSG00000288674.1     int64\n",
      "ENSG00000288675.1     int64\n",
      "Length: 60670, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#opening the fixed table\n",
    "import pandas as pd\n",
    "df = pd.read_csv('fixed_table', low_memory=False)\n",
    "df.drop(columns=df.columns[0], axis=1,inplace=True)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256e6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers (these patients have 1 and 0 days left until death, possibly skewing the results)\n",
    "df = df.drop([15, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5f902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#encoding data to be read as floats rather than objects\n",
    "df['demographic_id'] = le.fit_transform(df['demographic_id'])\n",
    "df['vital_status'] = le.fit_transform(df['vital_status'])\n",
    "df['paper_clinical_stage'] = le.fit_transform(df['paper_clinical_stage'])\n",
    "#E.g. vital_status has been encoded to be 0 for alive and 1 for dead\n",
    "deadPatients = df[df['vital_status'] != 0]\n",
    "alivePatients = df[df['vital_status'] == 0]\n",
    "print(df['vital_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271eb3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age_at_diagnosis  age_at_index  days_to_birth  year_of_birth  \\\n",
      "0             25041            68         -25041           1940   \n",
      "1             21901            59         -21901           1952   \n",
      "2             30643            83         -30643           1926   \n",
      "\n",
      "   demographic_id  paper_clinical_stage  ENSG00000000003.15  \\\n",
      "0              43                     0                4511   \n",
      "1              16                     0                6035   \n",
      "2              11                     2                5583   \n",
      "\n",
      "   ENSG00000000005.6  ENSG00000000419.13  ENSG00000000457.14  ...  \\\n",
      "0                402                1433                 201  ...   \n",
      "1                 23                1886                 775  ...   \n",
      "2                  8                2542                 946  ...   \n",
      "\n",
      "   ENSG00000288661.1  ENSG00000288662.1  ENSG00000288663.1  ENSG00000288665.1  \\\n",
      "0                  0                  0                  4                  0   \n",
      "1                  0                  0                 70                  0   \n",
      "2                  0                  0                 38                  0   \n",
      "\n",
      "   ENSG00000288667.1  ENSG00000288669.1  ENSG00000288670.1  ENSG00000288671.1  \\\n",
      "0                  0                  8                 77                  0   \n",
      "1                  2                  0                110                  0   \n",
      "2                  0                  0                342                  0   \n",
      "\n",
      "   ENSG00000288674.1  ENSG00000288675.1  \n",
      "0                  4                 60  \n",
      "1                  9                 59  \n",
      "2                  3                 23  \n",
      "\n",
      "[3 rows x 60666 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "Name: vital_status, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#preparing the data in X and y sets\n",
    "X = df.drop(columns = ['initial_weight','vital_status', 'year_of_death','days_to_death'])\n",
    "y = df['vital_status']\n",
    "X2 = deadPatients.drop(columns = ['initial_weight','vital_status', 'year_of_death','days_to_death'])\n",
    "y2 = deadPatients['days_to_death']\n",
    "\n",
    "print(X.head(3))\n",
    "print(y.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bdee86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing data into sets to be trained and tested at a 20% test size\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size = 0.2)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2.values, y2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c032d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "X2_train = sc.fit_transform(X2_train)\n",
    "X2_test = sc.fit_transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca558675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Decision Tree Classifier 1.0\n",
      "1 - Random Forest Classifier 1.0\n",
      "2 - SVC (linear k) 1.0\n",
      "3 - SVC (RBF) 0.9772727272727273\n",
      "4 - Logistic Regression 1.0\n",
      "5 - Gaussian NB 1.0\n",
      "6 - K-Neighbours 0.75\n"
     ]
    }
   ],
   "source": [
    "#Preparing and training the models\n",
    "#Creating a function to train all models at once\n",
    "\n",
    "def models(X_train, y_train):\n",
    "    #0 = Decision Tree Classifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    dtc.fit(X_train,y_train)\n",
    "    \n",
    "    #1 = Random Forest Classifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rfc = RandomForestClassifier(n_estimators=10, criterion = 'entropy', random_state = 0)\n",
    "    rfc.fit(X_train,y_train)\n",
    "\n",
    "    #2 = SVC (linear k)\n",
    "    from sklearn.svm import SVC\n",
    "    svc_ln = SVC(kernel='linear', random_state = 0)\n",
    "    svc_ln.fit(X_train,y_train)\n",
    "    \n",
    "    #3 = SVC (RBF)\n",
    "    from sklearn.svm import SVC\n",
    "    svc_rbf = SVC(kernel='rbf', random_state = 0)\n",
    "    svc_rbf.fit(X_train,y_train)\n",
    "\n",
    "    #4 = Logistic Regression\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lreg = LogisticRegression(random_state = 0)\n",
    "    lreg.fit(X_train,y_train)\n",
    "\n",
    "    #5 = Gaussian NB\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "\n",
    "    #6 = K-Neighbours\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knc = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "    knc.fit(X_train,y_train)\n",
    "    \n",
    "    #print the accuracy of each model\n",
    "    print('0 - Decision Tree Classifier', dtc.score(X_train, y_train))\n",
    "    print('1 - Random Forest Classifier', rfc.score(X_train, y_train))\n",
    "    print('2 - SVC (linear k)', svc_ln.score(X_train, y_train))\n",
    "    print('3 - SVC (RBF)', svc_rbf.score(X_train, y_train))\n",
    "    print('4 - Logistic Regression', lreg.score(X_train, y_train))\n",
    "    print('5 - Gaussian NB', gnb.score(X_train, y_train))\n",
    "    print('6 - K-Neighbours', knc.score(X_train, y_train))\n",
    "    \n",
    "    return dtc, rfc, svc_ln, svc_rbf, lreg, gnb, knc\n",
    "\n",
    "model = models(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c69306f2",
   "metadata": {},
   "source": [
    "#Saving models\n",
    "import joblib\n",
    "joblib.dump(model[0], 'Decision Tree Classifier')\n",
    "joblib.dump(model[1], 'Random Forest Classifier')\n",
    "joblib.dump(model[2], 'SVC (linear k)')\n",
    "joblib.dump(model[3], 'SVC (RBF)')\n",
    "joblib.dump(model[4], 'Logistic Regression')\n",
    "joblib.dump(model[5], 'Gaussian NB')\n",
    "joblib.dump(model[6], 'K-Neighbours')\n",
    "print(\"Models saved successfully\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47621077",
   "metadata": {},
   "source": [
    "#Loading models\n",
    "import joblib\n",
    "import numpy as np\n",
    "models = np.empty(7, dtype=object)\n",
    "models[0] = joblib.load('Decision Tree Classifier')\n",
    "models[1] = joblib.load('Random Forest Classifier')\n",
    "models[2] = joblib.load('SVC (linear k)')\n",
    "models[3] = joblib.load('SVC (RBF)')\n",
    "models[4] = joblib.load('Logistic Regression')\n",
    "models[5] = joblib.load('Gaussian NB')\n",
    "models[6] = joblib.load('K-Neighbours')\n",
    "\n",
    "model = models\n",
    "print(\"Models Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391b0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [3 2]]\n",
      "Model[0] Testing Accuracy = \"0.5454545454545454\" \n",
      "\n",
      "[[3 3]\n",
      " [2 3]]\n",
      "Model[1] Testing Accuracy = \"0.5454545454545454\" \n",
      "\n",
      "[[1 5]\n",
      " [1 4]]\n",
      "Model[2] Testing Accuracy = \"0.45454545454545453\" \n",
      "\n",
      "[[0 6]\n",
      " [0 5]]\n",
      "Model[3] Testing Accuracy = \"0.45454545454545453\" \n",
      "\n",
      "[[1 5]\n",
      " [1 4]]\n",
      "Model[4] Testing Accuracy = \"0.45454545454545453\" \n",
      "\n",
      "[[0 6]\n",
      " [0 5]]\n",
      "Model[5] Testing Accuracy = \"0.45454545454545453\" \n",
      "\n",
      "[[1 5]\n",
      " [0 5]]\n",
      "Model[6] Testing Accuracy = \"0.5454545454545454\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in range(len(model)):\n",
    "    cm = confusion_matrix(y_test, model[i].predict(X_test))\n",
    "    \n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, model[i].predict(X_test)).ravel()\n",
    "    \n",
    "    score = (TP+TN)/(TP+TN+FN+FP)\n",
    "    print(cm)\n",
    "    print('Model[{}] Testing Accuracy = \"{}\"'.format(i, score),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b19b68d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0 = Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "daysToDeathModel = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "daysToDeathModel.fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b90364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3115.,  481.,  148.,  541., 2680., 3115.,  911.,  522.,  541.,\n",
       "        418., 2043.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daysPrediction = daysToDeathModel.predict(X_test)\n",
    "daysPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63bf8a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient predicted to be Dead\n",
      "\t correct prediction, prediction of days left for this patient: 3115\n",
      "Patient predicted to be Dead\n",
      "\t correct prediction, prediction of days left for this patient: 481\n",
      "Patient predicted to be Alive\n",
      "\t incorrect prediction - Patient is dead.\n",
      "Patient predicted to be Dead\n",
      "\t incorrect prediction - Patient is alive\n",
      "Patient predicted to be Alive\n",
      "\t correct prediction\n",
      "Patient predicted to be Alive\n",
      "\t correct prediction\n",
      "Patient predicted to be Dead\n",
      "\t correct prediction, prediction of days left for this patient: 911\n",
      "Patient predicted to be Dead\n",
      "\t incorrect prediction - Patient is alive\n",
      "Patient predicted to be Alive\n",
      "\t incorrect prediction - Patient is dead.\n",
      "Patient predicted to be Dead\n",
      "\t incorrect prediction - Patient is alive\n",
      "Patient predicted to be Alive\n",
      "\t correct prediction\n",
      "28    1\n",
      "8     1\n",
      "53    1\n",
      "5     0\n",
      "24    0\n",
      "56    0\n",
      "34    1\n",
      "45    0\n",
      "19    1\n",
      "39    0\n",
      "50    0\n",
      "Name: vital_status, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test)):\n",
    "    if model[1].predict([X_test[i]]) == 0:\n",
    "        print(\"Patient predicted to be Alive\")\n",
    "        if(y_test.iloc[i]==0):\n",
    "            print(\"\\t correct prediction\")\n",
    "        else:\n",
    "            print(\"\\t incorrect prediction - Patient is dead.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Patient predicted to be Dead\")\n",
    "        if(y_test.iloc[i]==1):\n",
    "            print(\"\\t correct prediction, prediction of days left for this patient: {}\".format(int(daysPrediction[i])))\n",
    "        else:\n",
    "            print(\"\\t incorrect prediction - Patient is alive\")\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
